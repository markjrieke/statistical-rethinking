---
title: "Missing Data and Other Opportunities"
output: github_document
---

* Consider three pancakes. One is burnt on both sides (BB). One is burnt on one side (BU). And one is wholly unburnt (UU). If you are served a pancake and the side face up is burnt, what is the probability the other side is burnt?
* The intuitive answer is one half --- but intuition misleads us!

$$
\begin{align*}
\text{Pr(burnt down|burnt up)} & = \frac{\text{Pr(burnt up & burnt down)}}{\text{Pr(burnt up)}} \\
& = \frac{1/3}{1/2} \\
& = \frac{2}{3}
\end{align*}
$$

* We can also confirm this via simulation:

```{r}
# simulate pancake & return rancomly ordered sides
sim_pancake <- function() {
  
  pancake <- sample(1:3, 1)
  sides <- matrix(c(1, 1, 1, 0, 0, 0), 2, 3)[,pancake]
  sample(sides)
  
}

# sim 10,000 pancakes
pancakes <- replicate(1e4, sim_pancake())
up <- pancakes[1,]
down <- pancakes[2,]

# compute proportion 1/1 (BB) out of all 1/1 and 1/0
num_11_10 <- sum(up == 1)
num_11 <- sum(up == 1 & down == 1)
num_11/num_11_10
```

* This is just a matter of counting *sides* rather than *pancakes*.
* Probability theory is not difficult mathematically --- it's just counting! The difficulty is in the interpretation/application.
* Two commonplace applications that aren't difficult mathematically but need some work are including *measurement error* in models, and using *Bayesian imputation* to account for *missing data*. 

## 15.1 Measurement error

* Let's look back at the divorce/marriage data from chapter 5.

```{r}
library(rethinking)
set_ulam_cmdstan(FALSE)

data(WaffleDivorce)
d <- WaffleDivorce

# points
plot(d$Divorce ~ d$MedianAgeMarriage,
     ylim = c(4, 15),
     xlab = "Median age marriage",
     ylab = "Divorce rate")

# standard errors
for (i in 1:nrow(d)) {
  
  ci <- d$Divorce[i] + c(-1, 1)*d$Divorce.SE[i]
  x <- d$MedianAgeMarriage[i]
  lines(c(x, x), ci)
  
}
```

* There's lots of variation in the measured divorce rate! Since the standard errors for some states are smaller, we could reasonably expect that the model's estimate for that state's rate would also be smaller. 

### 15.1.1 Error on the outcome

* Let's reintroduce the causal model and include an observation error on the outcome:

```{r}
library(dagitty)

marriage <-
  dagitty(
    "dag{
      D [unobserved]
      e_D [unobserved]
      A -> M
      A -> D
      M -> D
      D -> D_obs
      e_D -> D_obs
    }"
  )

coordinates(marriage) <-
  list(x = c(A = 1, M = 2, D = 2, D_obs = 3, e_D = 4),
       y = c(A = 2, M = 1, D = 3, D_obs = 3, e_D = 3))

drawdag(marriage)
```

* In this version of the DAG, age at marriage & marriage rate causally influence the divorce rate. We don't observe the true divorce rate, but we do observe $D_{obs}$, which is a function of both D and some error, $\text{e}_D$.
* The key benefit of Bayes is that we can simply put parameters in the gaps in our knowledge (i.e., the true divorce rate):

$$
\begin{align*}
D_{\text{OBS}[i]} & \sim \text{Normal}(D_{\text{TRUE}[i]}, D_{\text{SE}[i]}) \\
D_{\text{TRUE}[i]} & \sim \text{Normal}(\mu_i, \sigma) \\
\mu_i & = \alpha + \beta_A A_A + \beta_M M_M \\
\alpha & \sim \text{Normal}(0,\ 0.2) \\
\beta_A & \sim \text{Normal}(0, \ 0.5) \\
\beta_M & \sim \text{Normal}(0, \ 0.5) \\
\sigma & \sim \text{Exponential}(1)
\end{align*}
$$

* Here, the true divorce rates just become a parameter in the distribution for the observed divorce rate.
* This also allows information to flow in both directions --- the uncertainty in measurement influences the regression parameters and the regression parameters influence the uncertainty in the measurements.

```{r}
# prep for stan
dlist <- 
  list(
    D_obs = standardize(d$Divorce),
    D_sd = d$Divorce.SE / sd(d$Divorce),
    M = standardize(d$Marriage),
    A = standardize(d$MedianAgeMarriage),
    N = nrow(d)
  )

# model!
m15.1 <-
  ulam(
    alist(
      # model
      D_obs ~ dnorm(D_true, D_sd),
      vector[N]:D_true ~ dnorm(mu, sigma),
      mu <- a + bA*A + bM*M,
      
      # priors
      a ~ dnorm(0, 0.25),
      bA ~ dnorm(0, 0.5),
      bM ~ dnorm(0, 0.5),
      sigma ~ dexp(1)
    ),
    
    data = dlist,
    chains = 4,
    cores = 4
  )

precis(m15.1, depth = 2)
```

>Note here the use of `vector[N]`. I'm not 100% sure why, but this the whole thing sample faster & with fewer diagnostic problems than a non-vectorized version.

* The old model from chapter 5 ound that `bA` was about -1 --- now it's almost half that, but still reliably negative. Errors in measuremetn can sometimes exaggerate effects or diminish them, depending on the context!
* Look at figure 15.2 on page 495 to see *shrinkage* in action --- less certain estimates are improved by pooling information with more certain estimates. 

### 15.1.2 Error on both outcome and predictor

* What about when there's measurement error on a predictor as well?
* We can do the same as before!

```{r}
marriage <-
  dagitty(
    "dag{
      M [unobserved]
      D [unobserved]
      e_M [unobserved]
      e_D [unobserved]
      A -> M
      A -> D
      M -> D
      D -> D_obs
      M -> M_obs
      e_D -> D_obs
      e_M -> M_obs
    }"
  )

coordinates(marriage) <-
  list(x = c(A = 1, M = 2, D = 2, M_obs = 3, D_obs = 3, e_M = 4, e_D = 4),
       y = c(A = 2, M = 1, D = 3, M_obs = 1, D_obs = 3, e_M = 1, e_D = 3))

drawdag(marriage)
```

* Fitting the model is much like before:

```{r}
# prep data for stan
dlist <-
  list(
    D_obs = standardize(d$Divorce),
    D_sd = d$Divorce.SE/sd(d$Divorce),
    M_obs = standardize(d$Marriage),
    M_sd = d$Marriage.SE/sd(d$Marriage),
    A = standardize(d$MedianAgeMarriage),
    N = nrow(d)
  )

# model!
m15.2 <-
  ulam(
    alist(
      # model
      D_obs ~ dnorm(D_true, D_sd),
      vector[N]:D_true ~ dnorm(mu, sigma),
      mu <- a + bA*A + bM*M_true[i],
      M_obs ~ dnorm(M_true, M_sd),
      vector[N]:M_true ~ dnorm(0, 1),
      
      # priors
      a ~ dnorm(0, 0.2),
      bA ~ dnorm(0, 0.5),
      bM ~ dnorm(0, 0.5),
      sigma ~ dexp(1)
    ),
    
    data = dlist,
    chains = 4,
    cores = 4
  )

precis(m15.2, depth = 2)
```

* The shrinkage here didn't change the inference on the divorce rate, but it idd update the estimates of marriage rate:

```{r}
post <- extract.samples(m15.2)
D_true <- apply(post$D_true, 2, mean)
M_true <- apply(post$M_true, 2, mean)
plot(dlist$M_obs,
     dlist$D_obs,
     pch = 16, 
     col = rangi2,
     xlab = "marriage rate (std)",
     ylab = "divorce rate (std)")

points(M_true, D_true)
for (i in 1:nrow(d)) 
  lines(c(dlist$M_obs[i], M_true[i]),
        c(dlist$D_obs[i], D_true[i]))
```

* The big take-home point is that when you have a distribution of values, don't reduce it down to a single value to use in a regression! Incorporate the entire uncertainty. 

### 15.1.3 Measurement terrors

* In the previous example, there are no new confounds introduced by the errors, but this isn't always the case!
* consider the following DAG --- the errors on $D$ and $M$ are correlated through an influence by $P$:

```{r}
marriage <- 
  dagitty(
    "dag{
      M [unobserved]
      D [unobserved]
      e_M [unobserved]
      e_D [unobserved]
      A -> M
      A -> D
      M -> D
      M -> M_obs
      D -> D_obs
      e_M -> M_obs
      e_D -> D_obs
      P -> e_M
      P -> e_D
    }"
  )

coordinates(marriage) <-
  list(x = c(A = 1, M = 2, D = 2, M_obs = 3, D_obs = 3, e_M = 4, e_D = 4, P = 5),
       y = c(A = 1, M = 0, D = 2, M_obs = 0, D_obs = 2, e_M = 0, e_D = 2, P = 1))

drawdag(marriage)
```

* Naively regressing $D_{obs}$ on $M_{obs}$ opens a non causal path through $P$. 
* If we have information on the measurement process and can model the true variables $D$ and $M$, there's hope, but we need to consider the covariance between the errors. 
* Another potential case:

```{r}
marriage <-
  dagitty(
    "dag{
      M [unobserved]
      D [unobserved]
      e_M [unobserved]
      e_D [unobserved]
      A -> M
      A -> D
      M -> D
      M -> e_D
      M -> M_obs
      D -> D_obs
      e_M -> M_obs
      e_D -> D_obs
    }"
  )

coordinates(marriage) <-
  list(x = c(A = 1, M = 2, M_obs = 3, e_M = 4, D = 2, D_obs = 3, e_D = 4),
       y = c(A = 1, M = 0, M_obs = 0, e_M = 0, D = 2, D_obs = 2, e_D = 2))

drawdag(marriage)
```

* This might occur if, say, marriages are rare. Then there aren't as many couples that could possibly get divorced, so the smaller sample size induces a larger error on the measurement of the divorce rate. 
* If we can average over the uncertainty in the true $M$ and $D$ using information about the measurement process, we might do alright. 
* Another worry is when a causal variable is measured less precisely than a non-causal one. 
*Let's say for example that we know $D$ and $M$ very precisely but now $A$ is measured with error. Let's also assume $M$ has zero causal impact on $D$:

```{r}
marriage <-
  dagitty(
    "dag{
      e_A [unobserved]
      A [unobserved]
      e_A -> A_obs
      A -> A_obs
      A -> M
      A -> D
    }"
  )

coordinates(marriage) <-
  list(x = c(e_A = 1, A_obs = 2, A = 3, M = 4, D = 4),
       y = c(e_A = 1, A_obs = 1, A = 1, M = 0, D = 2))

drawdag(marriage)
```

* If we plop a regression of $D$ on $A_{obs}$ and $M$ it'll suggest that $M$ *strongly* influences $D$. This is because $M$ contains proxy information about the true $A$, but measured much more precisely than $A_{obs}$. 
* Here's a simulation to show the example:

```{r}
N <- 500
A <- rnorm(N)
M <- rnorm(N, -A)
D <- rnorm(N, A)
A_obs <- rnorm(N, A)

plot(M, D)
```

## 15.2 Missing Data

* The insight from measurement error is to realize that any uncertain piece of data can be replaced with a distribution that reflects that uncertainty, but what about when data is simply missing?
* So far, we've just been doing *complete case analysis*. 
* Another common response to missing data is to replace with an assumed value --- like the mean, median, or some assumed value like 0. 
* Neither is truly safe --- complete case throws away data & fixed imputation means the model will think it knows an unknown value with absolute certainty. 
* If we think causally about missingness, we may be able to use the model to *impute* missing values. 
* Some rethinking: missing data are still meaningful data. The fact that a variable has an unobserved value is still an observation. Thinking about the process that caused missingness can help solve big problems.

### 15.2.1 DAG ate my homework

* Let's consider a sample of students who own dogs. The students homework $H$ is influenced by how much each student studies $S$. 

```{r}
N <- 100
S <- rnorm(N)

# grade students on a 10-point scale, influenced by S
H <- rbinom(N, size = 10, inv_logit(S))
```

* Then, oh-no! some dogs eat some homework. We'll encode the missingness as a 0/1 indicator $D$. 
* When homework has been eaten, we cannot observe the true distribution of homework, but we do get to observe the incomplete case $H^*$.
* In DAG form, $H \rightarrow H^* \leftarrow D$. 
* If we want to learn the influence of $S$ on $H$ we have to rely on $H^*$ --- we're relying on $S \rightarrow H^*$ being a good approximation for $S \rightarrow H$. 
* How good this assumption is depends on the cause of the missing values --- let's consider 4 scenarios considered as DAGs.

```{r}
# Case 1: missing completely at random (simplest case)
case_1 <-
  dagitty(
    "dag{
      H [unobserved]
      S -> H
      D -> Hm
      H -> Hm
    }"
  )

coordinates(case_1) <-
  list(x = c(S = 1, D = 1, H = 2, Hm = 2),
       y = c(S = 1, D = 2, H = 1, Hm = 2))

drawdag(case_1)

# simulate case 1
D <- rbern(N)
Hm <- H
Hm[D == 1] <- NA

Hm
```

* We now have `NA` scattered about the dataset --- is this a problem? We can decide by considering whether the outcome $H$ is independent of $D$. In this case, $H$ is independent of $D$ because $H^*$ is a collider.
* Another way of thinking about it --- random missingness doesn't change the overall distribution of homework scores & therefore doesn't bias our estimate on the causal effect of studying. 

```{r}
# Case 2: Studying influences whether or not dog eats homework
# (maybe studying a lot means less playtime with the dog, who gets restless)
case_2 <-
  dagitty(
    "dag{
      H [unobserved]
      S -> H
      S -> D
      D -> Hm
      H -> Hm
    }"
  )

coordinates(case_2) <-
  coordinates(case_1)

drawdag(case_2)

D <- ifelse(S > 0, 1, 0)
Hm <- H
Hm[D == 1] <- NA

Hm
```

* In this second case the missingness is *not* random --- every student who studies more than average is missing homework!
* There is now also a non-causal backdoor path from $H \rightarrow H^* \leftarrow D \leftarrow S$. We close this path by conditioning on $S$ (which we wanted to do anyway). 

```{r}
# Case 3: influence on both H and D
# say X is noise in the student's house 
# noisier houses produce worse homework and dogs more likely to misbehave
case_3 <-
  dagitty(
    "dag{
      H [unobserved]
      X [unobserved]
      S -> H
      X -> H
      X -> D
      D -> Hm
      H -> Hm
    }"
  )

coordinates(case_3) <-
  list(x = c(S = 1, D = 1, X = 2, H = 3, Hm = 3),
       y = c(S = 1, D = 3, X = 2, H = 1, Hm = 3))

drawdag(case_3)

set.seed(501)
N <- 1000
X <- rnorm(N)
S <- rnorm(N)
H <- rbinom(N, size = 10, inv_logit(2 + S - 2*X))
D <- ifelse(X > 1, 1, 0)
Hm <- H
Hm[D == 1] <- NA
Hm
```

* Here, regressing $H^*$ on $S$ introduces a new non-causal path: $H^* \leftarrow D \leftarrow X \rightarrow H$.
* Let's first see what we gt if we fully observe $H$. We haven't observed $X$ so we can't put it into the model. 

```{r}
dat_list <-
  list(
    H = H,
    S = S
  )

m15.3 <-
  ulam(
    alist(
      H ~ binomial(10 ,p),
      logit(p) <- a + bS*S,
      a ~ normal(0, 1),
      bS ~ normal(0, 0.5)
    ),
    
    data = dat_list,
    chains = 4
  )

precis(m15.3)
```

* The true coefficient on $S$ should be 1 --- this estimate is way off! This used the complete data $H$ so it can't be the missingness --- this is a case of *omitted variable bias*. 
* What impact does the missing data have?

```{r}
dat_list0 <-
  list(
    H = H[D == 0],
    S = S[D == 0]
  )

m15.4 <-
  ulam(
    alist(
      H ~ binomial(10, p),
      logit(p) <- a + bS*S,
      a ~ normal(0, 1),
      bS ~ normal(0, 0.5)
    ),
    
    data = dat_list0,
    chains = 4
  )

precis(m15.4)
```

* The estimate here actually gets better (still not at 1)! But how? 
* Since the missingness is caused in part by noise, the dataset with removed houses actually removes some of the omitted variable bias.
* This is not a general property of missing data in a DAG of this type --- if the function for missingness is the following, the estimate gets worse:

```{r}
D <- ifelse(abs(X) < 1, 1, 0)

dat_list0mod <- 
  list(
    H = H[D == 0],
    S = S[D == 0]
  )

m15.4mod <- 
  ulam(
    alist(
      H ~ binomial(10, p),
      logit(p) <- a + bS*S,
      a ~ normal(0, 1),
      bS ~ normal(0, 1)
    ),
    
    data = dat_list0mod,
    chains = 4
  )

precis(m15.4mod)
```

```{r}
# Case 4: Much ado about nothing
# here, let's say the quality of homework influences whether or not a dog eats it
# (just roll with it)
case_4 <-
  dagitty(
    "dag{
      H [unobserved]
      S -> H
      H -> D
      D -> Hm
      H -> Hm
    }"
  )

coordinates(case_4) <-
  coordinates(case_1)

drawdag(case_4)

N <- 100
S <- rnorm(N)
H <- rbinom(N, size = 10, inv_logit(S))
D <- ifelse(H < 5, 1, 0)
Hm <- H
Hm[D == 1] <- NA
Hm
```

* Here, there's not much at all we can do! There's nothing we can condition on to block the non-causal path $S \rightarrow H \rightarrow D \rightarrow H^*$.
* The point here is to illustrate the diverse consequences of missing data and the importance of exploring our own scenarios.
* Even when we cannot completely eliminate the impact of missing data, we may be able to show through simulation that the impact is small. 

### 15.2.2 Imputing primates

* *Imputation* allows us to (hopefully) avoid biased information and also use all the observed data. 
* In any generative model, information about variables is explained by the model regardless of whether or not the data is observed. 
* Let's return to the primate milk example from chapter 5, where we used a *complete case* analysis. 
* Let's say $M$ is body mass, $B$ is neocortex percent, $K$ is milk energy, and $U$ is an unobserved variable:

```{r}
milk_basic <-
  dagitty(
    "dag{
      U [unobserved]
      U -> M
      U -> B
      M -> K
      B -> K
    }"
  )

coordinates(milk_basic) <-
  list(x = c(M = 1, U = 2, K = 2, B = 3),
       y = c(M = 1, U = 1, K = 2, B = 1))

drawdag(milk_basic)
```

* Instead of having all these values directly, we have the observed $B^*$ that includes some missing values.
* We don't know what process causes the missingness, so let's consider some different DAGs that model the process of $B^*$ based on $R_B$ --- a variable that indicates the species has missing values. 
* First --- let's consider the hypothesis that $R_B$ is missing at random --- there are no variables that influence it. 

```{r}
milk_1 <- 
  dagitty(
    "dag{
      U [unobserved]
      B [unobserved]
      U -> M
      U -> B
      M -> K
      B -> K
      B -> Bm
      R_B -> Bm
    }"
  )

coordinates(milk_1) <-
  list(x = c(M = 1, R_B = 2, U = 2, K = 2, Bm = 3, B = 3),
       y = c(M = 1, R_B = 0, U = 1, K = 2, Bm = 0, B = 1))

drawdag(milk_1)
```

* Next, the body mass influences which species have missing values. This could happen if smaller primates are less often studied than larger ones.
* This introduces a non-causal path $B^* \leftarrow R_B \leftarrow M \rightarrow K$, but conditioning on $M$ blocks this path. 

```{r}
milk_2 <- 
  dagitty(
    "dag{
      U [unobserved]
      B [unobserved]
      U -> M
      U -> B
      M -> R_B
      M -> K
      B -> K
      B -> Bm
      R_B -> Bm
    }"
  )

coordinates(milk_2) <-
  coordinates(milk_1)

drawdag(milk_2)
```

* Finally, let's consider that the brain size itself influences $R_B$. This could be because anthropologists are more interested in large-brained species. 
* If this is true, we won't be able to test --- the influence of $B \rightarrow K$ will be biased via a non-causal path through $R_B$. 
* The statistical trick with Bayesian imputation is to model the variable with missing values. Each missing value receives a unique parameter --- the observed data gives us a prior.
* Here, for example, we might have:

$$
\begin{gather}
B = [0.55, \ B_2, \ B_3, \ B_4, \ 0.65, \ 0.65, \ \dots, \ 0.76, \ 0.75]
\end{gather}
$$

* The simplest model for missing $B$ values will just draw from its own normal distribution:

$$
\begin{align*}
K_i & \sim \text{Normal}(\mu_i, \sigma) \\
\mu_i & = \alpha + \beta_B B_i + \beta_M \ \text{log} \ M_i \\
\color{orange}{B_i} & \color{orange}{\sim} \color{orange}{\text{Normal}(\nu, \sigma_B)} \\
\alpha & \sim \text{Normal}(0, 0.5) \\
\beta_B & \sim \text{Normal}(0, 0.5) \\
\beta_M & \sim \text{Normal}(0, 0.5) \\
\sigma & \sim \text{Exponential}(1) \\
\nu & \sim \text{Normal}(0.5, 1) \\
\sigma_B & \sim \text{Exponential}(1)
\end{align*}
$$

* This model ignores that $B$ and $M$ are associated through $U$. But let's start with this just to keep things simple. 
* The interpretation of $B_i \sim \text{Normal}(\nu, \sigma_B)$ is a bit weird. 
* When $B_i$ is observed, this is a likelihood. When it's missing, it's a prior. 
* In this case, $B$ is bound by 0 and 1, so a normal distribution might not be the best choice, but let's just roll with it. 
* All implementations of imputation are a bit awkward --- since the locations of missing values have to be respected, it comes down to a lot of index management. `ulam()` handles a lot of this for us.

```{r}
# load & prep data for stan
data(milk)
d <- milk
d$neocortex.prop <- d$neocortex.perc/100
d$logmass <- log(d$mass)

dat_list <-
  list(
    K = standardize(d$kcal.per.g),
    B = standardize(d$neocortex.prop),
    M = standardize(d$logmass)
  )

# model!
m15.5 <-
  ulam(
    alist(
      K ~ dnorm(mu, sigma),
      mu <- a + bB*B + bM*M,
      B ~ dnorm(nu, sigma_B),
      c(a, nu) ~ dnorm(0, 0.5),
      c(bB, bM) ~ dnorm(0, 0.5),
      sigma_B ~ dexp(1),
      sigma ~ dexp(1)
    ),
    
    data = dat_list,
    chains = 4,
    cores = 4
  )

precis(m15.5, depth = 2)
```

* We get a parameter for each of the missing values! McElreath injects a function into the stan code to handle the accounting of keeping track of the indices:

```{r}
stancode(m15.5)
```

* Let's compare this to a model that drops the missing cases.

```{r}
obs_idx <- which(!is.na(d$neocortex.prop))

dat_list_obs <-
  list(
    K = dat_list$K[obs_idx],
    B = dat_list$B[obs_idx],
    M = dat_list$M[obs_idx]
  )

m15.6 <-
  ulam(
    alist(
      # model
      K ~ dnorm(mu, sigma), 
      mu <- a + bB*B + bM*M,
      
      # missing (but it's not!)
      B ~ dnorm(nu, sigma_B),
      
      # priors
      c(a, nu) ~ dnorm(0, 0.5),
      c(bB, bM) ~ dnorm(0, 0.5),
      sigma_B ~ dexp(1),
      sigma ~ dexp(1)
    ),
    
    data = dat_list_obs,
    chains = 4,
    cores = 4
  )
```

* If we compare the parameter estimates --- the model that imputes missing values, `m15.5`, has a narrower marginal distribution than the model that just drops cases, `m15.6`. This is because it's using more data!

```{r}
plot(coeftab(m15.5, m15.6), pars = c("bB", "bM"))
```

* We can also compare the imputed values alongside the non-missing values:

```{r}
# get imputed values + ci
post <- extract.samples(m15.5)
B_impute_mu <- apply(post$B_impute, 2, mean)
B_impute_ci <- apply(post$B_impute, 2, PI)

# B vs K
plot(dat_list$B,
     dat_list$K,
     pch = 16,
     col = rangi2,
     xlab = "neocortex percent (std)",
     ylab = "kcal milk (std)")

miss_idx <- which(is.na(dat_list$B))
Ki <- dat_list$K[miss_idx]
points(B_impute_mu, Ki)
for (i in 1:12) lines(B_impute_ci[,i], rep(Ki[i], 2))

# next one!
plot(dat_list$M,
     dat_list$B,
     pch = 16,
     col = rangi2,
     ylab = "neocortex percent (std)",
     xlab = "log body mass (std)")

Mi <- dat_list$M[miss_idx]
points(Mi, B_impute_mu)
for (i in 1:12) lines(rep(Mi[i], 2), B_impute_ci[,i])
```

* Note that in the second plot, the imputed values do not show an upward slope. This is because the imputation model assumed no relationship between the predictors.
* We can improve the model by changing the imputation model to estimate the relationship between the two predictors.
* To do so, we just use the relationship between the predictors as indicated by the DAG --- this just involves changing the imputation step for $B_i$ from a normal to a multivariate normal:

$$
\begin{gather}
(M_i, B_i) \sim \text{MVNormal}((\mu_M, \mu_B), S)
\end{gather}
$$

* This is the simplest model we could have used to describe the association between $M$ & $B$ --- it assumes that the covariance is enough to describe the relationship. 
* In `ulam()`, we have to construct a variable that includes both the observed $M$ values and the merged list of observed and imputed $B$ values. 

```{r}
m15.7 <-
  ulam(
    alist(
      # K as a function of B and M
      K ~ dnorm(mu, sigma),
      mu <- a + bB*B_merge + bM*M,
      
      # M & B correlation
      MB ~ multi_normal(c(muM, muB), Rho_BM, Sigma_BM),
      matrix[29,2]:MB <<- append_col(M, B_merge),
      
      # define B_merge as a mix of observed and imputed values
      vector[29]:B_merge <- merge_missing(B, B_impute),
      
      # priors
      c(a, muB, muM) ~ dnorm(0, 0.5),
      c(bB, bM) ~ dnorm(0, 0.5),
      sigma ~ dexp(1),
      Rho_BM ~ lkj_corr(2),
      Sigma_BM ~ dexp(1)
    ),
    
    data = dat_list,
    chains = 4,
    cores = 4
  )

precis(m15.7, depth = 3, pars = c("bM", "bB", "Rho_BM"))
```

* The slopes for `bM` and `bB` haven't changed too much, but if we look at the parameter comparison plot, we can see a positive association between the predictors (including the imputed ones):

```{r}
# get imputed values + ci
post <- extract.samples(m15.7)
B_impute_mu <- apply(post$B_impute, 2, mean)
B_impute_ci <- apply(post$B_impute, 2, PI)

miss_idx <- which(is.na(dat_list$B))
Ki <- dat_list$K[miss_idx]

# next one!
plot(dat_list$M,
     dat_list$B,
     pch = 16,
     col = rangi2,
     ylab = "neocortex percent (std)",
     xlab = "log body mass (std)")

Mi <- dat_list$M[miss_idx]
points(Mi, B_impute_mu)
for (i in 1:12) lines(rep(Mi[i], 2), B_impute_ci[,i])
```

* This is clearly doing better and doing better is good!
* Some rethinking, *multiple imputation* gets used a lot in frequentist settings and is a bit more limited than full on Bayesian imputation, but you'll still see it in the wild. 
* Some overthinking with the stan code:

```{r}
stancode(m15.5)
```

* The function at the top merges a vector of observed values with a vector of parameters to stand in the place of missing values.
* If you use `ulam()`, the `B_missidx` vector is built for you, but if you use stan directly you'll need to build it yourself and pass to Stan as data:

```{r}
B_missidx <- which(is.na(dat_list$B))
B_missidx
```

### 15.2.3 Where is your god now?

* Sometimes there aren't statistical solutions to scientific problems, but in these cases we can still use statistical thinking to tell us there is no statistical solution!
* As an example, in some religions God punishes the wicked and rewards the just --- these are "moralizing gods." In others, gods behave independently from humans.
* One question might be --- does such a difference in belief have any consequences for society? Say, do societies with moralizing gods grow faster/tend to replace societies with less moralizing gods?

```{r}
data("Moralizing_gods")
str(Moralizing_gods)
```

* The `population` is on the log scale for different regions (`polity`) across different centuries (`year`). 
* `moralizing_gods` can be 1 for yes, 0 for no, or `NA` for unknown.
* Does belief in moralizing gods increase the rate of population growth? 
* This is a tough causal cookie --- there are many unobserved confounds. But if we (incorrectly) assume that the year moralizing gods appear in a society, we can sort of treat the problem as a *regression disontinuity* one. 
* There are *a lot* of missing values here:

```{r}
table(Moralizing_gods$moralizing_gods, useNA = "always")
```

* There's a lot of missing data, many 1s, and only a few 0s --- remember that the impact of missing data depends on the process that produced them. 
* Plotting may help visualize the problem:

```{r}
symbol <- ifelse(Moralizing_gods$moralizing_gods == 1, 16, 1)
symbol <- ifelse(is.na(Moralizing_gods$moralizing_gods), 4, symbol)
color <- ifelse(is.na(Moralizing_gods$moralizing_gods), "black", rangi2)
plot(Moralizing_gods$year,
     Moralizing_gods$population,
     pch = symbol,
     col = color,
     xlab = "Time (year)",
     ylab = "Population size",
     lwd = 1.5)
```

* Filled blue points are the presence of moralizing gods while open blue points are the presence of other types of gods. X's are missing!
* This is highly non-random! Written records are usually needed to determine historical religious beliefs:

```{r}
with(Moralizing_gods,
     table(gods = moralizing_gods, literacy = writing, useNA = "always"))
```

* The majority of the missing values are for non-literate polities --- no writing means no evidence of any kind, generally. 
* This situation can't be saved by statistics, but it's useful to reason as to why. 
* Could we just drop the missing values & use a *complete case analysis*? Probably not! This will bias our inference.
* An optimistic DAG might be:

```{r}
gods <-
  dagitty(
    "dag{
      G [unobserved]
      G -> P
      G -> Gm
      P -> W
      W -> R_G
      R_G -> Gm
    }"
  )

coordinates(gods) <-
  list(x = c(P = 1, W = 1.5, G = 2, R_G = 2.5, Gm = 3),
       y = c(P = 1, W = 2, G = 1, R_G = 2, Gm = 1))

drawdag(gods)
```

* Here, $P$ is the rate of population growth (not population size shown in the dataset), $G$ is the presence of belief in moralizing gods, $Gm$ is the observed variable with missing values, $W$ is writing, and $R_G$ is the missing values indicator. 
* This is optimistic because it assumes there are no unobserved confounds.
* We want to know if the outcome, $P$, is independent of missingness, $R_G$. 
* This is clearly not a dog-eats-homework at random scenario --- $R_G$ is not missing randomly. $R_G$ is assumed to be explained by $W$, which is (unfortunately) influenced by $P$. If we condition on $W$ it could make things worse (it'd be like conditioning on the outcome variable), since $P \rightarrow W$. Conditioning on $R_G$ would not help --- there's no structural reason to trust an estimate of $Gm \rightarrow P$. 
* If we could somehow condition on $G$ instead of $Gm$, we'd be in the clear. But we need to have a good approximation of the generative model of the variable, for which there's no obvious answer.
* For example, Hawaii was a large complex polity with moralizing gods by 1778 --- the year that James Cook & his crew finally made contact:

```{r}
haw <- which(Moralizing_gods$polity == "Big Island Hawaii")
columns <- c("year", "writing", "moralizing_gods")
t(Moralizing_gods[haw, columns])
```

* After contact, Hawaii is correctly coded with 1 for a belief in moralizing gods. But there's no direct evidence of when these gods came into Hawaii's society, since Hawaii had no writing system of its own. 
* An imputation model would *have* to make very strong assumptions. 
* One (unfortunately common) method might be to just assume that moralizing gods aren't present when the value is missing. This procedure results in biased estimates. 
* In principle, we could perform model based imputation for the missing values, but we don't have any obviously correct way to do this. We can't just associate the presence/absence of moralizing gods with population size, because that's the very question under investigation!
* Our statistical investigation leads us to the conclusion that more research is needed to replace the `NA`s with observations!
* Another obstacle to imputing the `moralizing_gods` variable: it's discrete! This is computationally trickier than imputing continuous variables. 

## 15.3 Categorical errors and discrete absences

* Previous examples focused on nice continuous variables --- discrete variables are a bit more difficult.
* Discrete variables don't produce a smooth surface for HMC to glide around on & discrete jumps are difficult to calibrate, so chains tend to get stuck for long periods.
* To get around this, we can use a *weighted average* to remove discrete parameters from the model. We sample the other parameters, then use their samples to compute the posterior for the removed discrete parameter.

### 15.3.1 Discrete cats

* Imagine a neighborhood in which every house contains a songbird. Let's survey the neighborhood & count the number of notes each bird sings in one minute.
* Some houses have cats, which may affect the amount each bird sings. In some cases, it's easy to tell if a house has a cat (because the cat is there) or not (because someone lets you know). In about 20%, though, you can't determine if there is or isn't a cat.

```{r}
cats <-
  dagitty(
    "dag{
      C [unobserved]
      R_C -> Cm
      C -> Cm
      C -> N
    }"
  )

coordinates(cats) <-
  list(x = c(R_C = 1, Cm = 2, C = 3, N = 4),
       y = c(R_C = 0, Cm = 0, C = 0, N = 0))

drawdag(cats)
```

* Here, the presence/absence of a cat $C$ influences the number of notes sung $N$. Because of missing values $R_C$, however, we only observe $C^*$. A generative model of the DAG might be:

$$
\begin{align*}
N_i & \sim \text{Poisson}(\lambda_i) \\
\text{log} \ \lambda_i & = \alpha + \beta C_i \\
C_i & \sim \text{Bernoulli}(k) \\
R_{C, i} & \sim \text{Bernoulli}(r)
\end{align*}
$$

```{r}
set.seed(9)

# set true parameters
N_houses <- 100L
alpha <- 5
beta <- -3
k <- 0.5
r <- 0.2

# simulate observations
cat <- rbern(N_houses, k)
notes <- rpois(N_houses, alpha + beta*cat)
R_C <- rbern(N_houses, r)
cat_obs <- cat
cat_obs[R_C == 1] <- -9L

# prep for stan
dat <-
  list(
    notes = notes,
    cat = cat_obs,
    RC = R_C,
    N = as.integer(N_houses)
  )
```

* Here, each unknown value of `cat_obs` is replaced with `-9`. The model should skip these anyway, but it's useful to set to some invalid value in case there's a bug & the model tries to sample them. In this case, `cat` is drawn from a Bernoulli distribution, so if the model ever asks for the probability of observing -9, there will be an error!
* We can't declare a parameter for each unobserved cat, so we instead average over the uncertainty in whether the cat was there or not.

$$
\begin{align*}
\Pr(N_i) & = \Pr(C_i = 1) \ \Pr(N_i | C_i = 1) + \Pr(C_i = 0) \ \Pr(N_i | C_i = 0) 
\end{align*}
$$

* When we don't know $C_i$, we compute the likelihood of $N_i$ for each possible $C_i$ then average the likelihoods with the probabilities that $C_i$ takes on each value.

```{r}
m15.8 <-
  ulam(
    alist(
      # singing bird model
      ## cat known present/absent:
      notes|RC==0 ~ poisson(lambda),
      log(lambda) <- a + b*cat,
      ## cat NA
      notes|RC==1 ~ custom(log_sum_exp(
        log(k) + poisson_lpmf(notes | exp(a + b)),
        log(1 - k) + poisson_lpmf(notes | exp(a))
      )),
      
      # priors
      a ~ normal(0, 1),
      b ~ normal(0, 0.5),
      
      # sneaking cat model
      cat|RC==0 ~ bernoulli(k),
      k ~ beta(2, 2)
    ),
    
    data = dat,
    chains = 4,
    cores = 4
  )

precis(m15.8)
```

* The likelihood gets split --- `notes|RC==0` reads as "the probability of $N$ when $R_C = 0$. This is our normal model when we know the cat's presence/absence.
* The next lines are for the average likelihood when the presence/absence isn't observed. It's basically just the previous line on the log scale.
* The sneaking cat presence/absence model is at the bottom --- when we know the presence/absence of the cat $R_C = 0$, we want to use that observation to update $k$, the probability that a cat is present. 
* Now let's see how we can check the presence/absence of any given cat, given that we know how many notes were sung:

$$
\begin{align*}
\Pr(C_i=1|N_i) & = \frac{\Pr(N_i|C_i=1)\ \Pr(C_i=1)}{\Pr(N_i|C_i=1)\ \Pr(C_i=1)+\Pr(N_i|C_i=0)\ \Pr(C_i=0)}
\end{align*}
$$

* Take a look closesly --- it's less threatening than it looks.
* We can have Stan calculate this for us in the *generated quantities* block:

```{r}
m15.9 <-
  ulam(
    alist(
      # singing bird model
      notes|RC==0 ~ poisson(lambda),
      notes|RC==1 ~ custom(log_sum_exp(
        log(k) + poisson_lpmf(notes | exp(a + b)),
        log(1 - k) + poisson_lpmf(notes | exp(a))
      )),
      log(lambda) <- a + b*cat,
      
      # priors
      a ~ normal(0, 1),
      b ~ normal(0, 0.5),
      
      # sneaking cat model
      cat|RC==0 ~ bernoulli(k),
      k ~ beta(2, 2),
      
      # imputed values
      gq> vector[N]:PrC1 <- exp(lpC1)/(exp(lpC1) + exp(lpC0)),
      gq> vector[N]:lpC1 <- log(k) + poisson_lpmf(notes[i] | exp(a + b)),
      gq> vector[N]:lpC0 <- log(1 - k) + poisson_lpmf(notes[i] | exp(a))
    ),
    
    data = dat,
    chains = 4,
    cores = 4
  )

# probability of the last few cats being present or nah
precis(m15.9, depth = 2)[293:303,]
```

```{r}
stancode(m15.9)
```

* The strategy extrapolates to discrete variables with more than two possible values --- you just need more than two terms in your average likelihood. For example, if houses can have up to two cats, the cats might be binomially distributed:

```{r, eval=FALSE}
notes|RC==1 ~ custom(log_sum_exp(
  binomial_lpmf(2 | 2, k) + poisson_lpmf(notes | exp(a + b*2)),
  binomial_lpmf(1 | 2, k) + poisson_lpmf(notes | exp(a + b*1)),
  binomial_lpmf(0 | 2, k) + poisson_lpmf(notes | exp(a + b*0))
))
```

* Unordered terms work the same way, but the leading terms would be from some simplex of probabilities. 
* We can also extend this to more than one discrete variable with missing values --- say there's also a variable for dog $D_i$ presence/absence. In this case, we can have 4 possible cases: 
  1. cat and dog
  2. cat
  3. dog
  4. neither cat nor dog (sad)
* If both the cat and dog variables are `NA`, we have to average over all four possibilities above, with prior terms for both cat and dog:

$$
\begin{align*}
\Pr(N_i) & = \Pr(C_i=1)\ \Pr(D_i=1)\ \Pr(N_i|C_i=1,D_i=1) \\
& \ + \Pr(C_i=1)\ \Pr(D_i=0)\ \Pr(N_i|C_i=1,D_i=0) \\
& \ + \Pr(C_i=0)\ \Pr(D_i=1)\ \Pr(N_i|C_i=0,D_i=1) \\
& \ + \Pr(C_i=0)\ \Pr(D_i=0)\ \Pr(N_i|C_i=0,D_i=0)
\end{align*}
$$

* If only the cat is `NA` and the dog is known present $D_i = 1$, then we only have to average over possibilities 1/3. 
* If only the dog is `NA` and the cat is known absent $C_i = 0$, then we only have to average over possibilities 3/4.
* In principle, this is algorithmic and easy. In practice, it makes for complicated code, since you have to account for all combinations of missingness & assign each a different average likelihood.
* We'll see this again in the next chapter when we encounter the *state space model*. State space models can have a large number of discrete or continuous unobserved variables.
* We typically don't write out each possibility explicitly in code, but instead use an algorithm to compute the average likelihood. 
* For example, in a *Hidden Markov Model*, an algorithm known as the *forward algorithm* does the averaging. You can read more in the Stan user manual.

### 15.3.2 Discrete error

* The example above concerned missing data, but when the data are measured with error, the procedure is very similar.

>Suppose for example that in the example above each house is assigned a probability of a cat being present. Call this probability $k_i$. When we are sure there is a cat there, $k_i = 1$. When we are sure there is no cat, $k_i = 0$. When we think it's a coin flip, $k_i = 0.5$. These $k_i$ values replace the parameter $k$ in the previous model, becoming weights for averaging our uncertainty.

## 15.4 Summary

* This chapter introduced the design and implementation of measurement error and missing data models. 
* Incorporating the cause of measurement error and missing data into a generative model helps decide how they impact inference & how we design a statistical procedure. 






